+++
title = "On craft and AI"
date = 2026-02-04
+++

In 2016, I stumbled across [otoro.net](https://otoro.net), which is still the gem now that it was then. The website is full of funky little neural networks doing all sorts of amazing stuff. And I love it.

I started programming when I was 9, in fourth grade. When I was a kid, I wanted to be a pilot or an illustrator. <span class=aside>Like for children’s books.</span> Maybe an aerospace engineer if flight school didn’t work out; but I didn’t want to be stuck on the ground.

When I was in fourth grade, the coolest club that existed, at least to me, was the stop motion animation club. I considered stop motion animation to be art, as illustration is an art, and as a budding artist, art was all I wanted to learn.

So I pleaded with my mom, and asked her whether she could sign me up for the stop motion animation club. And she tried to! But alas, the after school club was full... so she signed me up for what she found to be the most similar club, which happened to be the Scratch club. I was devastated.

Scratch is, you know, the block based programming language. At the time I saw Scratch as a duplo-like toy; I wanted legos. I saw it neither as a canvas for art or a medium for animation. So I played hooky and skipped the first four weeks.

After a month of missing the club, my mom finally got a call from the school— they didn’t know where I was. I told my mom that I was going home early because I didn’t want to stay for the club. She told me, “you signed up for the club, and Claytons aren’t quitters! The choice is yours.”

It did not feel like much of a choice. But I went anyway.

To my surprise, all my friends were there! Somehow it had never come up when hanging out at lunch or recess. 

I had a lot of fun! I learned that Scratch was in fact, a great medium for art and animation. Not only that, but it was a great medium for games and simulations! I discovered new types of art, like procedural art, and interactive art. I now know that my mom was on to something. <span class=aside>After typing scratch.mit.edu into the address bar a million times, I got curious about mit.edu too, to the point where I now go to school at MIT. (Yes, I went to MIT because I wanted to pick the featured projects on Scratch. No, I still don't have permission to do that yet.)</span> 

As a kid, until I was around eighth grade, my screen time at home was limited to 30 minutes a day. <span class=aside>Later, I think that changed to an hour. I’m very grateful for these limits, because I spent a lot more time outside and with my siblings and I would have without them, at this age.</span> So I would draw out games on paper, and write the code by hand to prepare for my little screen-time window. And when my screen time started, I would write (well, click-and-drag) the code as quickly as I could, and write down all the bugs I found on paper so I could debug and fix them before my next chance to work on the code the next day.

Programming is an art, programming is a craft. Later, I moved schools and fell in love with scheme and lisp and Paul Graham and his essays and writing about how his background in art shaped his view on programming. These ideas deeply resonated with me! I am an artist too, at heart.

In seventh grade, I wrote a neural network in Scratch. It was to play a volleyball game I wrote in Scratch, inspired by otoro.net. The matrix multiplications were done with lists and for loops, and the network weights were trained (found?) via genetic algorithm. <span class=aside>It was a small network, one layer deep, concatenating its past output to its current input at each time step.</span> One day I was allowed to use my parents’ computer, so I opened a pinned tab and left my genetic algorithm running overnight, with the screen brightness set to zero. I woke up very early to copy the final policy weights down by hand, before I closed the tab and snuck back to bed. I manually entered the weight checkpoint into the network the next day (during my screen time window) and lo and behold, the policy had learned to play volleyball! Never before or since have I been so amazed by what a little code can do.

My uncle was in town one week, and I excitedly showed him my volley-ball-playing neural network. He thought it was cool! And then I showed him how it worked, all done in Scratch. He was horrified. A week later, I got a book or two on my doorstep, and a note from my uncle. The first book was *Think Python*; the note was a suggestion to learn numpy after mastering the basics in that book.

Numpy was magical. What took many nested for loops and tricky indexing became a single line of code. As I fell in love with the world of neural networks, I dug up old blog posts and websites about good-old-fashioned AI (GOFAI), and the magical world of lisp and scheme and prolog.

Having just learned Python, I came across Norvig's guide on how to write a lisp in Python. I was hooked. Programming languages were just programs, and I finally felt good enough at programming to (begin to) understand how programming languages worked! This is when I really started getting into compilers, and compilers all start as labors of love.

I read about Ruby and Smalltalk, the lambda papers that gave rise to scheme, and Graydon toiling away at Rust. In eighth grade, I made a friend who wrote a lot of Java. He joked that Python wasn't as "real" as Java. I decided to learn the hardest coolest language I could think of, and according to the cool older functional programming PL nerds I hung around online, that language, around 2018, was Rust. I digress.

But this experience of honing a craft and falling in love with the complex emergent behavior of dynamic systems left me with two takeaways at the time, which today seem to be in constant tension:

1. Programming is an art, it is about craftsmanship. About finding the simplest solution, but no simpler; [managing essential and accidental complexity](https://curtclifton.net/papers/MoseleyMarks06a.pdf); developing a deeper understanding of math and abstraction and hardware to write crisp and beautiful code. Good code reads like poetry, or a [koan](http://www.catb.org/jargon/html/koans.html).

2. Neural networks are art, and machine learning is beautifully emergent. You find all these strange little interstitial spaces in the latents. The subject is fractal-like in complexity, small building blocks compose: [CNNs](https://distill.pub/2017/feature-visualization/) are used by both GANs to generate images, and [RND](https://arxiv.org/abs/1810.12894) to explore new environments. The most beautiful ideas are often the most elegant, and the most impossible.

These are the two camps that raised me, and now they seem to be at war. I understand both angles of the argument, and I'm just not quite sure how to slice it:

1. On the one hand, I hate AI slop. I feel it eating away at the craft of programming. I very strongly believe that people should not build emotional relationships with AI. If you need a conversation partner, that's what other people are for. With respect to the current generation of models, it seems dangerous for people to treat them like anything other than sharp tools to be handled carefully, if at all.

2. On the other hand, when used as a tool, AI can be deeply transformative. For example, I had a PDF, a few hundred poorly-scanned low-resolution pages of an old book, that I could never accurately OCR. Then Gemini 3 Flash (or whatever) came out; I uploaded the PDF, and OCR'd the whole thing to well-formatted Markdown in a few minutes! The same goes for upscaling images, vectorizing drawings I've done by hand, or downloading and organizing reams of poorly-structured data. AI is too sharp of a tool to ignore, in these cases.

When thinking of AI as a tool, I like to relate it to a hammer. You can use a hammer to nail nails. Alternatively, you can use a hammer to bash heads in. Fortunately, most people choose not to. We didn't prevent people from using hammers for bad things by getting rid of hammers and going back to pounding nails in with stone. The moral equivalent of bashing heads in is a poor use of any tool. AI is here to stay, and people will misuse it. As with hammers, there is no such thing as a technological solution to a social problem. 

<span class=aside>Of course, we should always ask who builds the hammers. I'm focusing here on the purely aesthetic and technical degradation of the craft, rather than the very real externalities and incentive structures around of model training, which deserve their own separate treatment. (Also, hammers don't hallucinate fingers when you ask for painted nails.)</span>

Many smart people whom I deeply respect have opposing views on the matter. I'm working to navigate this tension. I want to learn new tools while staying true to my roots. I want to keep the bar for quality high, and find strange points in the latent space instead of defaulting to mode collapse. The world is going to continue to change quickly; unless we rethink the way we relate to technology and one another, we are going to be caught so off-guard and become oh-so-lost.

We exist on something of a knife's edge, with respect to the way the future may go:

- On one side, technology continually decreases human agency. We end up with something like the matrix, but worse, because it's not dystopian for the people inside it, but as pleasurable and addictive as it is shallow; something like VR headsets RLHF'd on the brain's dopamine response. (This looks like reels, not wobbling black-and-white spirals.)

- On the other side is a future where technology fades into the background and increases human agency; technology becomes a silent enabler of greater offline connection, bridging people and spaces together, to exchange different slices of the same idea, to build a greater picture of the whole. Technology is a tool people may choose to use to understand the world, their actions, and their action's consequences, while allowing them to experience the consequence of their actions and choose to live one best life among many great possibilities.

<!-- NOTE: Chris Rytting: what is possible shapes what people do. Messaging allows people to meet up, but it also encourages people to text instead of talk. Tradeoffs -->

I'd like to be standing on that knife's edge, and with the little leverage I have, push as hard as I can so that things fall to the side of increasing human agency, rather than the other way around.

I am not fully sure I know what the right answer is. Or if there is one, for that matter. I want to grow spaces that increase human agency. To do that, we need two things:

- First, we need organizations with sound incentive structures. We need to design games where everyone wins the more we play them. Consider two farms, one run by unpaid prisoners and the other by unpaid volunteers. Both may produce the same amount of produce. Which farm has better internal structure? <span class=aside>I want to say it's the one where people choose to be there.</span>

- Second, if we want these agency-preserving spaces to win, they must also have better asymptotics than worse spaces, in the long run. <span class=aside>Asymptotics in the O(n) vs O(n²) sense.</span> These good spaces must use resources more effectively to outcompete spaces driven by perverse incentive structures. The volunteer run farm must produce more produce at a cheaper cost *and* be beneficial to the people in its sphere. 

Furthermore, these spaces must respect agency, which naturally implies that people may choose to leave. If you want people to stay, or if you'd like for more people to join, you have to design a space that is better than any other option, both internally and externally. These types of spaces are both rare and valuable.

I'm not just making up stories about farms here. Having the knife's-edge balance fall in favor of increasing human agency requires designing games with aligned incentive structures and better asymptotics for growth. I have a lot of thoughts queued up on how to do this, as there's a lot to unpack here. I will publish a post about this soon.

On otoro.net, there's this little volleyball game. Two little blobs, each with their own little neural network, play volleyball with one another, forever. This game directly inspired my recreation attempt in Scratch. The otoro.net website and its wonderful little blobs taught me that programming is an art, and learning is a craft. Even if discourse diverges, I can always return to the shared roots of making art and honing my craft. 

With that in mind, here are things I've decided to do, as I navigate this tension: 

1. All my communication with others will be words that are spoken or typed myself. I will always be clear about the provenance of code and prose, and will never publish any AI-generated prose on this website. <span class=aside>The worst possible outcome is a world where two people are texting one another, with a serialization step to corporate-style email via LLM in between. It's like talking to someone through a lawyer, but worse; at least lawyers are accountable. Just say what you want to say.</span>

2. I will make more art, and do so with others. I want to carve out some great corner of ideaspace, together. I long for a world where people are free to share valuable aesthetic contributions: to beautify the earth, the spaces we inhabit, and the relationships between the people that inhabit them. To choose to both be in a position of high agency and, when faced with many conflicting choices, to choose good.

Which roots do you find yourself returning to?

---

If you made it this far, you deserve another fun post. Here's one I enjoyed a while back:

<div class=boxed>

**Daily reading: [Jepsen, Datomic Pro 1.0.7075](https://jepsen.io/analyses/datomic-pro-1.0.7075)**

Datalog is awesome, and datomic really shows off the power of clojure. I always enjoy reading a good Jepsen test, so I hope you enjoy this article!

</div>
